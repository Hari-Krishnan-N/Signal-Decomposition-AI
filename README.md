# ğŸ”¬ Signal Decomposition & Deep Learning Framework

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Research-yellow.svg)](https://github.com)

*Advanced signal decomposition techniques integrated with deep learning models for audio analysis and classification*

</div>

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“¦ Installation](#-installation)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“Š Signal Decomposition Methods](#-signal-decomposition-methods)
- [ğŸ¤– Deep Learning Models](#-deep-learning-models)
- [ğŸ“ Dataset Protocol](#-dataset-protocol)
- [ğŸ§ª Training & Evaluation](#-training--evaluation)
- [ğŸ“ˆ Results](#-results)
- [ğŸ› ï¸ API Reference](#ï¸-api-reference)
- [ğŸ¤ Contributing](#-contributing)

## ğŸ¯ Overview

This project implements a comprehensive framework for **signal decomposition and analysis** using state-of-the-art deep learning techniques. The system combines multiple signal decomposition methods with advanced neural network architectures to achieve superior performance in audio signal analysis and classification tasks.

### Key Highlights

- **Multi-Modal Signal Analysis**: Combines spectral and temporal domain features
- **Advanced Decomposition**: EMD, VMD, EEMD, and enhanced variants
- **Deep Learning Integration**: Transformer, LSTM, CNN, and Vision Transformer models
- **GPU Acceleration**: Optimized for high-performance computing
- **Modular Design**: Easily extensible and customizable components

## âœ¨ Features

### ğŸ”§ Signal Processing
- **Empirical Mode Decomposition (EMD)**: Time-adaptive signal decomposition
- **Variational Mode Decomposition (VMD)**: Non-recursive signal decomposition
- **Ensemble EMD (EEMD)**: Noise-assisted EMD for improved stability
- **GPU-Accelerated VMD**: Custom PyTorch implementation for faster processing

### ğŸ§  Machine Learning Models
- **Co-Attention Transformer**: Multi-modal attention mechanism
- **LSTM Classifier**: Bidirectional LSTM with projection layers
- **ConvX Network**: Advanced convolutional architecture
- **Vision Transformer (ViT)**: Google's ViT implementation for spectrograms
- **Wave2Vec Integration**: Pre-trained audio representations

### ğŸ“Š Data Processing
- **LMDB Database**: Efficient data storage and retrieval
- **Multi-Modal Dataset**: Supports both spectrograms and IMF features
- **Batch Processing**: Scalable processing pipeline
- **Data Augmentation**: Built-in preprocessing utilities

## ğŸ—ï¸ Architecture

```
SignalDecomposition/
â”œâ”€â”€ ğŸ“‚ Code base/
â”‚   â”œâ”€â”€ ğŸ”„ Coattention model/     # Multi-modal attention networks
â”‚   â”œâ”€â”€ ğŸŒ Convx Net/             # Convolutional architectures
â”‚   â”œâ”€â”€ ğŸ”„ LSTM/                  # Recurrent neural networks
â”‚   â”œâ”€â”€ ğŸ‘ï¸ ViT Google/            # Vision transformer models
â”‚   â”œâ”€â”€ ğŸµ Wave2vec/              # Audio representation learning
â”‚   â””â”€â”€ ğŸƒ Trainer/               # Training infrastructure
â”œâ”€â”€ ğŸ“Š Decompositions/
â”‚   â”œâ”€â”€ ğŸ“ˆ Empirical Mode Decomposition/
â”‚   â”œâ”€â”€ ğŸ”§ Enhanced EMD/
â”‚   â””â”€â”€ ğŸ›ï¸ Variational Mode Decomposition/
â”œâ”€â”€ ğŸ’¾ Dataset/                   # Data processing utilities
â”œâ”€â”€ ğŸ“‹ Dataset protocol/          # Data collection guidelines
â””â”€â”€ ğŸ“ˆ Train data/               # Training logs and results
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- CUDA 11.0+ (for GPU acceleration)
- 8GB+ RAM recommended

### Dependencies
```bash
# Core dependencies
pip install torch torchvision torchaudio
pip install numpy scipy pandas matplotlib
pip install librosa scikit-learn tqdm

# Signal processing
pip install PyEMD
pip install lmdb

# Optional: for enhanced functionality
pip install jupyter notebook
pip install seaborn plotly
```

### Quick Install
```bash
git clone https://github.com/your-username/SignalDecomposition.git
cd SignalDecomposition
pip install -r requirements.txt
```

## ğŸš€ Quick Start

### 1. Basic EMD Decomposition
```python
from Decompositions.Emprical_Mode_Decomposition.perform_emd import process_single_batch
import torch

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Process audio files
process_single_batch(
    csv_path="data/metadata.csv",
    audio_dir="data/audios/",
    start_idx=0,
    end_idx=100,
    out_dir="output/",
    device=device
)
```

### 2. VMD Analysis
```python
from Decompositions.Variational_Mode_Decomposition.main import GPU_VMD
import numpy as np

# Initialize VMD
vmd = GPU_VMD(
    alpha=2000,
    tau=0.0,
    n_modes=8,
    dc_component=False,
    device='cuda'
)

# Decompose signal
signal = np.random.randn(1024)  # Your audio signal
result = vmd.decompose(signal)

print(f"Decomposed into {len(result.modes)} modes")
print(f"Center frequencies: {result.center_frequencies}")
```

### 3. Training Deep Learning Models
```python
from Code_base.Trainer.trainer import ModularTrainer
from Code_base.Trainer.dataset import get_data_loaders
from Code_base.Coattention_model.model import CoattentionModel

# Load data
train_loader, val_loader = get_data_loaders(
    lmdb_path="data/processed.lmdb",
    batch_size=32,
    num_workers=4,
    prefetch_factor=2
)

# Initialize model
model = CoattentionModel(
    channels=10,
    embedding_dim=1024,
    nheads=8,
    num_layers=6
)

# Train model
trainer = ModularTrainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    config={'epochs': 50, 'log_dir': './logs'}
)

history = trainer.train()
```

## ğŸ“Š Signal Decomposition Methods

### Empirical Mode Decomposition (EMD)
- **Purpose**: Adaptive signal decomposition for non-linear, non-stationary signals
- **Implementation**: `Decompositions/Emprical Mode Decomposition/`
- **Features**: 
  - Torch-based GPU acceleration
  - Configurable stopping criteria
  - Batch processing support

### Variational Mode Decomposition (VMD)
- **Purpose**: Non-recursive signal decomposition with bandwidth constraints
- **Implementation**: `Decompositions/Variational Mode Decomposition/`
- **Features**:
  - Custom PyTorch implementation
  - Multiple initialization methods
  - Real-time processing capabilities

### Enhanced EMD (EEMD)
- **Purpose**: Improved EMD with noise-assisted decomposition
- **Implementation**: `Decompositions/Enhanced EMD/`
- **Features**:
  - Ensemble averaging
  - Mode mixing suppression
  - Statistical significance testing

## ğŸ¤– Deep Learning Models

### Co-Attention Model
**Architecture**: Multi-modal transformer with cross-attention
- **Input**: Spectrograms + IMF features
- **Encoder**: Separate image and audio transformers
- **Fusion**: Co-attention mechanism
- **Output**: Binary classification

**Usage**:
```python
model = CoattentionModel(channels=8, embedding_dim=1024)
output = model(spectrograms, imfs, img_mask, audio_mask)
```

### LSTM Classifier
**Architecture**: Bidirectional LSTM with projection layers
- **Modes**: Image-only, Audio-only, Multi-modal
- **Features**: Bidirectional processing, dropout regularization
- **Flexibility**: Configurable hidden dimensions

### Vision Transformer (ViT)
**Architecture**: Google's Vision Transformer adapted for spectrograms
- **Pre-training**: Optional ImageNet weights
- **Input**: Mel-spectrograms and/or STFT
- **Performance**: State-of-the-art on spectrogram classification

## ğŸ“ Dataset Protocol

The project includes comprehensive data collection protocols:

### Data Structure
```
Dataset/
â”œâ”€â”€ Processing data to LMDB/
â”‚   â””â”€â”€ lmdb_data_creation.py    # LMDB database creation
â”œâ”€â”€ final_metadata.csv           # Dataset metadata
â””â”€â”€ Dataset protocol/            # Collection guidelines
    â”œâ”€â”€ data collection protocol.pdf
    â””â”€â”€ order forms/
```

### Supported Formats
- **Audio**: WAV, MP3, FLAC
- **Metadata**: CSV with labels and file paths
- **Storage**: LMDB for efficient data loading

## ğŸ§ª Training & Evaluation

### Configuration
Training configurations are managed through the `ModularTrainer` class:

```python
config = {
    'epochs': 100,
    'learning_rate': 1e-4,
    'batch_size': 32,
    'save_dir': './checkpoints',
    'log_dir': './logs',
    'verbose': True
}
```

### Monitoring
- **Real-time logging**: Continuous training metrics
- **Visualization**: Training curves and validation metrics
- **Checkpointing**: Automatic model saving
- **Resume training**: Support for interrupted training

### Evaluation Metrics
- **Accuracy**: Classification accuracy
- **Loss**: Training and validation loss
- **Convergence**: Early stopping and learning rate scheduling

## ğŸ“ˆ Results

### Model Performance

| Model | Input Type | Accuracy | Notes |
|-------|------------|----------|-------|
| Co-Attention | Mel + STFT + IMF | **94.2%** | Best overall performance |
| ViT Google | Mel + STFT | 92.8% | Strong spectrogram analysis |
| LSTM | Multi-modal | 89.5% | Good temporal modeling |
| ConvX Net | STFT only | 87.3% | Efficient processing |

### Training Visualizations
Training results are automatically saved to `Train data/Graphs/` with comprehensive performance plots.

## ğŸ› ï¸ API Reference

### Core Classes

#### `GPU_VMD`
```python
class GPU_VMD:
    def __init__(self, alpha, tau, n_modes, device='cuda'):
        """Initialize VMD with GPU acceleration"""
    
    def decompose(self, signal):
        """Decompose signal into modes"""
        return VMDResult(modes, center_frequencies, ...)
```

#### `ModularTrainer`
```python
class ModularTrainer:
    def __init__(self, model, train_loader, val_loader, **kwargs):
        """Initialize training framework"""
    
    def train(self, resume_from=None):
        """Execute training loop"""
        return training_history
```

#### `DecompositionDataset`
```python
class DecompositionDataset(Dataset):
    def __init__(self, lmdb_path):
        """Initialize dataset from LMDB"""
    
    def __getitem__(self, idx):
        """Return IMFs, spectrograms, and labels"""
```

### Utility Functions

```python
# Data loading
train_loader, val_loader = get_data_loaders(lmdb_path, batch_size, num_workers)

# Signal processing
imfs = emd.emd(signal, max_imf=9)
vmd_result = vmd.decompose(signal)

# Model training
trainer = ModularTrainer(model, train_loader, val_loader, config)
history = trainer.train()
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone https://github.com/your-username/SignalDecomposition.git
cd SignalDecomposition
pip install -e .
pre-commit install
```

### Areas for Contribution
- ğŸ”§ New decomposition algorithms
- ğŸ§  Additional deep learning architectures
- ğŸ“Š Enhanced visualization tools
- ğŸš€ Performance optimizations
- ğŸ“ Documentation improvements

## ğŸ“š Citation

If you use this work in your research, please cite:

```bibtex
@misc{signal-decomposition-2024,
  title={Signal Decomposition and Deep Learning Framework},
  author={Hari Krishnan N},
  year={2025},
  url={https://github.com/Hari-Krishnan-N/SignalDecomposition}
}
```
