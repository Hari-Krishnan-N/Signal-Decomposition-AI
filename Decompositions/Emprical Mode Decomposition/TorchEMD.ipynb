{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np \n",
    "from scipy.io import wavfile\n",
    "from scipy.interpolate import CubicSpline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# import torch\n",
    "# import numpy as np \n",
    "# from scipy.io import wavfile\n",
    "# from scipy.interpolate import CubicSpline\n",
    "# from scipy.signal import stft\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of zero crossings\n",
    "\n",
    "def count_zero_crossings(signal:torch.tensor):\n",
    "    return torch.sum(torch.diff(torch.sign(signal)) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the IMF for a residual\n",
    "\n",
    "def sift(residual:torch.tensor, max_iter:int=128, tol:float=1e-4, device:torch.device='cpu'):\n",
    "\n",
    "    h = residual\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        maxima = torch.where((h[:-2] < h[1:-1]) & (h[1:-1] > h[2:]))[0] + 1\n",
    "        minima = torch.where((h[:-2] > h[1:-1]) & (h[1:-1] < h[2:]))[0] + 1\n",
    "\n",
    "        if len(maxima) < 2 or len(minima) < 2:\n",
    "            break\n",
    "        \n",
    "        h = h.cpu().numpy()\n",
    "        maxima = maxima.cpu().numpy()\n",
    "        minima = minima.cpu().numpy()\n",
    "\n",
    "        upper_env = CubicSpline(maxima, h[maxima]) (torch.arange(len(h)))\n",
    "        lower_env = CubicSpline(minima, h[minima]) (torch.arange(len(h)))\n",
    "\n",
    "        h = torch.from_numpy(h).to(device)\n",
    "        upper_env = torch.from_numpy(upper_env).to(device)\n",
    "        lower_env = torch.from_numpy(lower_env).to(device)\n",
    "\n",
    "        mean_env = (upper_env + lower_env) / 2\n",
    "        new_h = h - mean_env\n",
    "\n",
    "        zero_crossings = count_zero_crossings(new_h)\n",
    "        extrema_count = len(maxima) + len(minima)\n",
    "        \n",
    "        if abs(zero_crossings - extrema_count) <= 1:\n",
    "            #print(f\"IMF found with {i + 1} iterations\")\n",
    "            return new_h\n",
    "        \n",
    "        h = new_h\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EMD\n",
    "\n",
    "def EmpricalModeDecomposition(signal:torch.tensor, max_imfs:int=10, device:torch.device='cpu'):\n",
    "\n",
    "    imfs = []\n",
    "    residual = signal\n",
    "\n",
    "    for _ in range(max_imfs):\n",
    "\n",
    "        imf = sift(residual, device=device)\n",
    "        imfs.append(imf)\n",
    "        residual -= imf\n",
    "\n",
    "        if torch.all(torch.abs(residual) < 1e-6):\n",
    "            break\n",
    "\n",
    "    return imfs, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the audio file\n",
    "\n",
    "def save_audio(data:torch.tensor, file_path:str, sample_rate:int, device:torch.device='cpu'):\n",
    "\n",
    "    data = (data / torch.max( torch.abs(data) ) ) * 32767\n",
    "\n",
    "    if device == 'cuda':\n",
    "        data = data.cpu()\n",
    "    data = data.numpy()\n",
    "\n",
    "    if np.isnan(data).any() or np.isinf(data).any():\n",
    "        data = np.nan_to_num(data)\n",
    "        return  \n",
    "    data = data.astype(np.int16)\n",
    "\n",
    "    wavfile.write(file_path, sample_rate, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conversion to mel  spectrogram\n",
    "\n",
    "# def hz_to_mel(hz):\n",
    "#     return 2595 * np.log10(1 + hz / 700.0)\n",
    "\n",
    "# def mel_to_hz(mel):\n",
    "#     return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "# def save_mel_spectrogram(signal:torch.tensor, sample_rate:int, save_path:str, device:torch.device='cpu'):\n",
    "\n",
    "#     n_mels = 512\n",
    "#     n_fft = 1024\n",
    "#     hop_length = 512\n",
    "\n",
    "#     mel_bins = np.linspace(hz_to_mel(0), hz_to_mel(sample_rate / 2), n_mels + 2)\n",
    "#     hz_bins = mel_to_hz(mel_bins)\n",
    "#     bin_idx = np.floor(hz_bins / (sample_rate / n_fft)).astype(int)\n",
    "    \n",
    "#     # Create the filter bank\n",
    "#     filter_bank = np.zeros((n_mels, n_fft // 2 + 1))\n",
    "#     for m in range(1, n_mels + 1):\n",
    "#         filter_bank[m - 1, bin_idx[m - 1]:bin_idx[m]] = np.linspace(0, 1, bin_idx[m] - bin_idx[m - 1])\n",
    "#         filter_bank[m - 1, bin_idx[m]:bin_idx[m + 1]] = np.linspace(1, 0, bin_idx[m + 1] - bin_idx[m])\n",
    "#     return filter_bank\n",
    "\n",
    "# # Compute STFT\n",
    "# f, t, Zxx = stft(signal, fs, nperseg=1024)\n",
    "# power_spectrogram = np.abs(Zxx)**2\n",
    "\n",
    "# # Convert to Mel scale\n",
    "# n_mels = 128\n",
    "# mel_filter = mel_filter_bank(n_mels, Zxx.shape[0] * 2, fs)\n",
    "# mel_spectrogram = np.dot(mel_filter, power_spectrogram)\n",
    "\n",
    "# # Plot the Mel spectrogram\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.imshow(10 * np.log10(mel_spectrogram + 1e-10), origin='lower', aspect='auto', cmap='magma', extent=[t[0], t[-1], 0, n_mels])\n",
    "# plt.colorbar(label='Power (dB)')\n",
    "# plt.title('Mel Spectrogram')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Mel bands')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a audio file, given path\n",
    "\n",
    "def process_audio(audio_path:str, save_path:str, min_val:int=None, max_val:int=None):\n",
    "    \n",
    "    sample_rate, data = wavfile.read(audio_path)\n",
    "    data = torch.tensor(data).type(torch.float32).to(device)\n",
    "    \n",
    "    if min_val and max_val:\n",
    "        data = (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    imfs, residual = EmpricalModeDecomposition(signal=data, device=device)\n",
    "    reconstructed = sum(imfs) + residual\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    for i, imf in enumerate(imfs):\n",
    "        imf_path = save_path + '/imf_' + str(i) + '.wav'\n",
    "        save_audio(data=imf, file_path=imf_path, sample_rate=sample_rate, device=device)\n",
    "    \n",
    "    residual_path = save_path + '/residual.wav'\n",
    "    save_audio(data=residual, file_path=residual_path, sample_rate=sample_rate, device=device)\n",
    "\n",
    "    reconstructed_path = save_path + '/reconstructed.wav'\n",
    "    save_audio(data=reconstructed, file_path=reconstructed_path, sample_rate=sample_rate, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single data point (trial)\n",
    "\n",
    "audio_path = '../../Dataset/neurovoz_v3/data/audios/HC_A1_0034.wav'\n",
    "save_path = '../../Dataset/EMD Audios/HC_A1_0034'\n",
    "\n",
    "process_audio(audio_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform EMD for all the data\n",
    "\n",
    "# inp_path = '../../Dataset/neurovoz_v3/data/audios'\n",
    "# out_path = '../../Dataset/EMD Audios'\n",
    "# files = list( os.listdir(inp_path))\n",
    "\n",
    "# with tqdm(enumerate(files), total=len(files)) as t:\n",
    "    \n",
    "#     for i, file in t:\n",
    "        \n",
    "#         audio_path = os.path.join(inp_path, file)\n",
    "#         save_path = os.path.join(out_path, file[:-4])\n",
    "        \n",
    "#         process_audio(audio_path=audio_path, save_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
