{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft, ifft, fftfreq\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r\"../Dataset/neurovoz_v3/data/audio_features/audio_features.csv\"\n",
    "audio_directory = r\"../Dataset/neurovoz_v3/data/audios\"\n",
    "imf_directory = r\"./Outputs/VMD/IMFs\"\n",
    "residual_directory = r\"./Outputs/VMD/Residual\"\n",
    "reconstructed_directory = r\"./Outputs/VMD/Reconstructed_Signal\"\n",
    "plot_directory = r\"./Outputs/VMD/Plots\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmd(signal, alpha=120, tau=0, K=5, DC=0, init=1, tol=1e-7):\n",
    "    print(\"VMD started\")\n",
    "    # Ensure signal is a numpy array\n",
    "    signal = np.array(signal, dtype=np.float64)\n",
    "    \n",
    "    # Normalize the signal (optional)\n",
    "    signal = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Perform VMD\n",
    "    modes, _, _ = vmdpy.VMD(signal, alpha, tau, K, DC, init, tol)\n",
    "    print(modes.shape)\n",
    "    # Reconstruct the signal from the modes\n",
    "    reconstructed_signal = np.sum(modes, axis=0, dtype=np.float64)\n",
    "    print(reconstructed_signal.shape)\n",
    "    # Calculate residual (signal minus reconstructed signal)\n",
    "    residual = signal - reconstructed_signal\n",
    "    print(\"VMD completed\")\n",
    "    return modes, residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def VMD_torch(f, alpha, tau, K, DC, init, tol, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Variational Mode Decomposition (VMD) implemented in PyTorch with device-agnostic initialization\n",
    "    and optimized FFT operations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    f : numpy.ndarray\n",
    "        Input signal (1D array).\n",
    "    alpha : float\n",
    "        Bandwidth constraint parameter.\n",
    "    tau : float\n",
    "        Lagrange multiplier for enforcing signal reconstruction fidelity.\n",
    "    K : int\n",
    "        Number of modes to decompose the signal into.\n",
    "    DC : bool\n",
    "        If True, constrain the first mode to have zero mean (DC component).\n",
    "    init : int\n",
    "        Initialization mode for center frequencies:\n",
    "        - 1: Linear initialization.\n",
    "        - 2: Random logarithmic initialization.\n",
    "        - 0: All frequencies start at zero.\n",
    "    tol : float\n",
    "        Convergence tolerance.\n",
    "    device : str, optional\n",
    "        Target device for computation ('cuda' or 'cpu'). Default is 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    u : numpy.ndarray\n",
    "        Decomposed modes in the time domain.\n",
    "    u_hat_final : numpy.ndarray\n",
    "        Fourier-domain representation of decomposed modes.\n",
    "    omega : numpy.ndarray\n",
    "        Center frequencies of the modes.\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    f = torch.tensor(f, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Ensure even length for the input signal\n",
    "    if len(f) % 2:\n",
    "        f = f[:-1]\n",
    "\n",
    "    # Period and sampling frequency of input signal\n",
    "    fs = torch.tensor(1.0 / len(f), device=device)\n",
    "    ltemp = len(f) // 2\n",
    "\n",
    "    # Create mirrored signal\n",
    "    fMirr = torch.empty(len(f) + 2 * ltemp, device=device)\n",
    "    fMirr[:ltemp] = torch.flip(f[:ltemp], dims=[0])\n",
    "    fMirr[ltemp:ltemp + len(f)] = f\n",
    "    fMirr[ltemp + len(f):] = torch.flip(f[-ltemp:], dims=[0])\n",
    "\n",
    "    # Time domain and spectral domain discretization\n",
    "    T = len(fMirr)\n",
    "    t = torch.arange(1, T + 1, device=device) / T\n",
    "    freqs = t - 0.5 - (1 / T)\n",
    "\n",
    "    # Clean up unnecessary tensors\n",
    "    del t, f\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Maximum number of iterations\n",
    "    Niter = 500\n",
    "    Alpha = torch.full((K,), alpha, device=device)\n",
    "\n",
    "    # Construct and center f_hat\n",
    "    f_hat = torch.fft.fftshift(torch.fft.fft(fMirr.contiguous()))\n",
    "    f_hat_plus = f_hat.clone()\n",
    "    f_hat_plus[:T // 2] = 0\n",
    "\n",
    "    # Clean up unnecessary tensors\n",
    "    del fMirr, f_hat\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Initialize omega_k\n",
    "    if init == 1:\n",
    "        omega_curr = torch.linspace(0, 0.5, K, device=device)\n",
    "    elif init == 2:\n",
    "        omega_curr = torch.sort(\n",
    "            torch.exp(\n",
    "                torch.log(fs) + \n",
    "                (torch.log(torch.tensor(0.5, device=device)) - torch.log(fs)) * torch.rand(K, device=device)\n",
    "            )\n",
    "        )[0]\n",
    "    else:\n",
    "        omega_curr = torch.zeros(K, device=device)\n",
    "\n",
    "    if DC:\n",
    "        omega_curr[0] = 0\n",
    "\n",
    "    lambda_curr = torch.zeros(len(freqs), dtype=torch.cfloat, device=device)\n",
    "    u_curr = torch.zeros((len(freqs), K), dtype=torch.cfloat, device=device)\n",
    "    u_prev = torch.zeros((len(freqs), K), dtype=torch.cfloat, device=device)\n",
    "    \n",
    "    omega_history = torch.zeros((Niter, K), device=device)\n",
    "    omega_history[0] = omega_curr\n",
    "\n",
    "    uDiff = tol + torch.finfo(torch.float32).eps\n",
    "    n = 0\n",
    "    sum_uk = torch.zeros(len(freqs), dtype=torch.cfloat, device=device)\n",
    "\n",
    "    while uDiff > tol and n < Niter - 1:\n",
    "        u_prev.copy_(u_curr)\n",
    "        \n",
    "        sum_uk = torch.sum(u_prev, dim=1) - u_prev[:, 0]\n",
    "        u_curr[:, 0] = (f_hat_plus - sum_uk - lambda_curr / 2) / (1 + Alpha[0] * (freqs - omega_curr[0]) ** 2)\n",
    "        \n",
    "        if not DC:\n",
    "            omega_curr[0] = (\n",
    "                torch.sum(freqs[T // 2:T] * (torch.abs(u_curr[T // 2:T, 0]) ** 2)) /\n",
    "                torch.sum(torch.abs(u_curr[T // 2:T, 0]) ** 2)\n",
    "            )\n",
    "\n",
    "        for k in range(1, K):\n",
    "            sum_uk += u_curr[:, k-1] - u_prev[:, k]\n",
    "            u_curr[:, k] = (f_hat_plus - sum_uk - lambda_curr / 2) / (1 + Alpha[k] * (freqs - omega_curr[k]) ** 2)\n",
    "            omega_curr[k] = (\n",
    "                torch.sum(freqs[T // 2:T] * (torch.abs(u_curr[T // 2:T, k]) ** 2)) /\n",
    "                torch.sum(torch.abs(u_curr[T // 2:T, k]) ** 2)\n",
    "            )\n",
    "\n",
    "        lambda_curr += tau * (torch.sum(u_curr, dim=1) - f_hat_plus)\n",
    "        omega_history[n + 1] = omega_curr\n",
    "        n += 1\n",
    "        uDiff = torch.sum(torch.abs(u_curr - u_prev) ** 2) / T\n",
    "\n",
    "    del freqs, f_hat_plus, lambda_curr\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    Niter = min(Niter, n)\n",
    "    omega = omega_history[:Niter]\n",
    "\n",
    "    u_hat = torch.zeros((T, K), dtype=torch.cfloat, device=device)\n",
    "    u_hat[T // 2:T, :] = u_curr[T // 2:T, :]\n",
    "    u_hat[1:T // 2, :] = torch.conj(torch.flip(u_curr[T // 2 + 1:T, :], dims=[0]))\n",
    "    u_hat[0, :] = torch.conj(u_hat[-1, :])\n",
    "\n",
    "    del u_curr, u_prev, omega_history\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    u = torch.zeros((K, T), device=device)\n",
    "    for k in range(K):\n",
    "        u[k] = torch.real(torch.fft.ifft(torch.fft.ifftshift(u_hat[:, k].contiguous())))\n",
    "\n",
    "    del u_hat\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    u = u[:, T // 4:3 * T // 4]\n",
    "\n",
    "    u_hat_final = torch.zeros((u.shape[1], K), dtype=torch.cfloat, device=device)\n",
    "    for k in range(K):\n",
    "        u_hat_final[:, k] = torch.fft.fftshift(torch.fft.fft(u[k].contiguous()))\n",
    "\n",
    "    return u.cpu().numpy(), u_hat_final.cpu().numpy(), omega.cpu().numpy()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample signal\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    f1, f2 = 2, 10\n",
    "    signal = np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t)\n",
    "    \n",
    "    # VMD parameters\n",
    "    alpha = 2000\n",
    "    tau = 0\n",
    "    K = 2\n",
    "    DC = False\n",
    "    init = 1\n",
    "    \n",
    "    # Decompose signal\n",
    "    modes, spectra, frequencies = VMD_torch(signal, alpha, tau, K, DC, init, 1e-6)\n",
    "    \n",
    "    print(f\"Number of modes extracted: {modes.shape[0]}\")\n",
    "    print(f\"Length of each mode: {modes.shape[1]}\")\n",
    "    print(f\"Final center frequencies: {frequencies[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_modes_and_reconstruct(modes, residual, sample_rate, original_signal, base_filename):\n",
    "    \"\"\"Save modes, residual, and reconstructed signal with length adjustment.\"\"\"\n",
    "    \n",
    "    reconstructed_signal = np.zeros_like(original_signal, dtype=np.float64)\n",
    "    \n",
    "    for i, mode in enumerate(modes[:5]):  \n",
    "    \n",
    "        mode = np.pad(mode, (0, len(original_signal) - len(mode)), 'constant')[:len(original_signal)]\n",
    "        mode_path = os.path.join(imf_directory, f\"{base_filename}_mode_{i+1}.wav\")\n",
    "        mode = (mode / np.max(np.abs(mode))) * 32767 if np.max(np.abs(mode)) > 0 else mode  # Normalize mode\n",
    "        mode = mode.astype(np.int16)\n",
    "        wavfile.write(mode_path, sample_rate, mode)\n",
    "        reconstructed_signal += mode\n",
    "\n",
    "    residual = np.pad(residual, (0, len(original_signal) - len(residual)), 'constant')[:len(original_signal)]\n",
    "    residual_path = os.path.join(residual_directory, f\"{base_filename}_residual.wav\")\n",
    "    wavfile.write(residual_path, sample_rate, residual.astype(np.int16))\n",
    "\n",
    "    reconstructed_signal += residual\n",
    "    if np.max(np.abs(reconstructed_signal)) > 0:\n",
    "        reconstructed_signal /= np.max(np.abs(reconstructed_signal)) \n",
    "\n",
    "    reconstructed_path = os.path.join(reconstructed_directory, f\"{base_filename}_reconstructed.wav\")\n",
    "    wavfile.write(reconstructed_path, sample_rate, (reconstructed_signal * 32767).astype(np.int16))\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, mode in enumerate(modes[:5]):\n",
    "        plt.subplot(6, 1, i+1)\n",
    "        plt.plot(mode)\n",
    "        plt.title(f\"Mode {i+1}\")\n",
    "    plt.subplot(6, 1, 6)\n",
    "    plt.plot(residual)\n",
    "    plt.title(\"Residual\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(plot_directory, f\"{base_filename}_modes_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_modes_and_reconstruct_vmd(modes, residual, sample_rate, original_signal, base_filename):\n",
    "\n",
    "    # Initialize reconstructed signal\n",
    "    reconstructed_signal = np.zeros_like(original_signal, dtype=np.float64)\n",
    "\n",
    "    # Save each mode\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Adjust mode length to match original signal\n",
    "        mode = np.pad(mode, (0, len(original_signal) - len(mode)), 'constant')[:len(original_signal)]\n",
    "\n",
    "        # Save mode as WAV\n",
    "        mode_path = os.path.join(imf_directory, f\"{base_filename}_mode_{i+1}.wav\")\n",
    "        if np.max(np.abs(mode)) > 0:\n",
    "            mode = (mode / np.max(np.abs(mode))) * 32767  # Normalize mode\n",
    "        mode = mode.astype(np.int16)\n",
    "        wavfile.write(mode_path, sample_rate, mode)\n",
    "\n",
    "        # Add to reconstructed signal\n",
    "        reconstructed_signal += mode\n",
    "\n",
    "    # Save residual\n",
    "    residual = np.pad(residual, (0, len(original_signal) - len(residual)), 'constant')[:len(original_signal)]\n",
    "    residual_path = os.path.join(residual_directory, f\"{base_filename}_residual.wav\")\n",
    "    residual = (residual / np.max(np.abs(residual))) * 32767 if np.max(np.abs(residual)) > 0 else residual\n",
    "    wavfile.write(residual_path, sample_rate, residual.astype(np.int16))\n",
    "\n",
    "    # Add residual to reconstructed signal\n",
    "    reconstructed_signal += residual\n",
    "    if np.max(np.abs(reconstructed_signal)) > 0:\n",
    "        reconstructed_signal /= np.max(np.abs(reconstructed_signal))\n",
    "\n",
    "    # Save reconstructed signal\n",
    "    reconstructed_path = os.path.join(reconstructed_directory, f\"{base_filename}_reconstructed.wav\")\n",
    "    wavfile.write(reconstructed_path, sample_rate, (reconstructed_signal * 32767).astype(np.int16))\n",
    "\n",
    "    # Plot modes and residual\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, mode in enumerate(modes[:5]):  # Limit to the first 5 modes for plotting\n",
    "        plt.subplot(6, 1, i+1)\n",
    "        plt.plot(mode, label=f\"Mode {i+1}\")\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.subplot(6, 1, 6)\n",
    "    plt.plot(residual, label=\"Residual\", color='red')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = os.path.join(plot_directory, f\"{base_filename}_modes_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(row):\n",
    "    \"\"\"\n",
    "    Process each audio file for VMD (Variational Mode Decomposition).\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): A dictionary containing audio file metadata (e.g., path).\n",
    "    \"\"\"\n",
    "    # Extract and clean the relative path\n",
    "    relative_path = row['AudioPath'].strip()\n",
    "    \n",
    "    if relative_path.startswith('../data/audios/'):\n",
    "        relative_path = relative_path.replace('../data/audios/', '')\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(audio_directory, relative_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Read the audio file\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "\n",
    "        # Convert stereo to mono if needed\n",
    "        if len(data.shape) == 2: \n",
    "            data = data[:, 0]\n",
    "            \n",
    "\n",
    "        # Normalize the data\n",
    "        data = data / np.max(np.abs(data))\n",
    "\n",
    "        # # Perform VMD\n",
    "        modes, residual, _ = VMD_torch(\n",
    "            f = data, \n",
    "            alpha=data.shape[0],  # adjust as needed\n",
    "            tau=0,       # noise-slack\n",
    "            K=8,         # number of modes\n",
    "            DC=False,     # keep zero frequency mode\n",
    "            init=1,      # uniformly distributed initial omegas\n",
    "            tol=1e-30     # convergence tolerance\n",
    "        )\n",
    "\n",
    "        # # Save the decomposed modes and reconstructed signal\n",
    "        # save_modes_and_reconstruct(modes, residual, sample_rate, data, base_filename)\n",
    "\n",
    "        # print(f\"Processed {base_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    process_audio_file(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Directory containing subfolders with audio files\n",
    "audio_directory = r\"C:\\Users\\Asus\\OneDrive - Amrita Vishwa Vidyapeetham\\Desktop\\biorun\\IMFs\\IMFS_VMD\"\n",
    "\n",
    "# Directory to save Mel spectrograms\n",
    "spectrogram_directory = r\"C:\\Users\\Asus\\OneDrive - Amrita Vishwa Vidyapeetham\\Desktop\\biorun\\Spectrograms\\VMD_S\"\n",
    "\n",
    "# Create the spectrogram directory if it doesn't exist\n",
    "if not os.path.exists(spectrogram_directory):\n",
    "    os.makedirs(spectrogram_directory)\n",
    "\n",
    "# Function to compute and save Mel spectrogram\n",
    "def save_mel_spectrogram(audio_data, sample_rate, output_path):\n",
    "    # Compute the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "\n",
    "    # Convert power spec to dB for visualization\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Plot the Mel spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spectrogram_db, sr=sample_rate, x_axis='time', y_axis='mel', fmax=8000)\n",
    "\n",
    "    # Remove the title, axis labels, and color bar\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# Function to process each audio file in the subfolders\n",
    "def process_audio_file(row):\n",
    "    \"\"\"\n",
    "    Process each audio file for VMD and generate Mel spectrogram.\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): A dictionary containing audio file metadata (e.g., path).\n",
    "    \"\"\"\n",
    "    # Extract and clean the relative path\n",
    "    relative_path = row['AudioPath'].strip()\n",
    "    if relative_path.startswith('../data/audios/'):\n",
    "        relative_path = relative_path.replace('../data/audios/', '')\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(audio_directory, relative_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    try:\n",
    "        # Read the audio file\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "\n",
    "        # Convert stereo to mono if needed\n",
    "        if len(data.shape) == 2: \n",
    "            data = data[:, 0]\n",
    "\n",
    "        # Normalize the data\n",
    "        data = data / np.max(np.abs(data))\n",
    "\n",
    "        # Create a folder to save the Mel spectrograms for this specific subfolder\n",
    "        subfolder_name = os.path.basename(os.path.dirname(file_path))\n",
    "        output_folder = os.path.join(spectrogram_directory, subfolder_name)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Create the output file path for the Mel spectrogram\n",
    "        spectrogram_file_name = base_filename + '_mel_spectrogram.png'\n",
    "        spectrogram_file_path = os.path.join(output_folder, spectrogram_file_name)\n",
    "\n",
    "        # Compute and save Mel spectrogram\n",
    "        save_mel_spectrogram(data, sample_rate, spectrogram_file_path)\n",
    "\n",
    "        print(f\"Mel Spectrogram saved: {spectrogram_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Iterate through each subfolder and audio file\n",
    "for root, dirs, files in os.walk(audio_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            # Construct the relative path for the file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), audio_directory)\n",
    "            row = {'AudioPath': relative_path}\n",
    "            \n",
    "            # Process the audio file\n",
    "            process_audio_file(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fft\n",
    "\n",
    "def vmd(signal, alpha=2000, tau=0, K=5, DC=0, init=None, tol=1e-6, device='cuda'):\n",
    "    \"\"\"\n",
    "    GPU-accelerated Variational Mode Decomposition (VMD)\n",
    "    \n",
    "    Args:\n",
    "        signal: Input signal (1D tensor).\n",
    "        alpha: Regularization parameter.\n",
    "        tau: Time step for dual ascent.\n",
    "        K: Number of modes.\n",
    "        DC: 0 for no DC component, 1 otherwise.\n",
    "        init: Initial values for modes and Lagrange multiplier.\n",
    "        tol: Convergence tolerance.\n",
    "        device: 'cuda' for GPU acceleration, 'cpu' otherwise.\n",
    "    \n",
    "    Returns:\n",
    "        modes: Decomposed modes (K x N tensor).\n",
    "    \"\"\"\n",
    "    # Move input signal to device\n",
    "    signal = torch.tensor(signal, dtype=torch.float32, device=device)\n",
    "    N = len(signal)\n",
    "    \n",
    "    # Fourier transform of the input signal\n",
    "    f_signal = torch.fft.fft(signal)\n",
    "    omega = torch.fft.fftfreq(N, d=1.0)\n",
    "    omega = omega.to(device)\n",
    "    \n",
    "    # Initialization\n",
    "    if init is None:\n",
    "        u = torch.zeros((K, N), device=device, dtype=torch.complex64)\n",
    "        omega_k = torch.linspace(0, torch.max(omega), K, device=device)\n",
    "    else:\n",
    "        u, omega_k = init\n",
    "    \n",
    "    # Lagrange multiplier\n",
    "    lambda_hat = torch.zeros(N, device=device, dtype=torch.complex64)\n",
    "    \n",
    "    # Dual ascent iterations\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        u_prev = u.clone()\n",
    "        \n",
    "        # Update each mode\n",
    "        for k in range(K):\n",
    "            # Construct denominator term\n",
    "            omega_shifted = omega - omega_k[k]\n",
    "            denominator = 1 + alpha * (omega_shifted ** 2)\n",
    "            \n",
    "            # Compute mode in Fourier domain\n",
    "            f_u_k = (f_signal - lambda_hat - torch.sum(u, dim=0) + u[k]) / denominator\n",
    "            u[k] = torch.fft.ifft(f_u_k).real\n",
    "        \n",
    "        # Update omega_k\n",
    "        for k in range(K):\n",
    "            omega_k[k] = torch.sum(torch.abs(u[k]) ** 2 * omega) / torch.sum(torch.abs(u[k]) ** 2)\n",
    "        \n",
    "        # Update Lagrange multiplier\n",
    "        residual = signal - torch.sum(u, dim=0).real\n",
    "        lambda_hat += tau * torch.fft.fft(residual)\n",
    "        \n",
    "        # Check convergence\n",
    "        if torch.norm(u - u_prev) < tol:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if iteration > 500:  # Prevent infinite loops\n",
    "            break\n",
    "    \n",
    "    return u.real.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Generate synthetic signal\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "    \n",
    "    # Run GPU-accelerated VMD\n",
    "    modes = vmd(signal, K=5, device='cuda')\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.plot(t, signal, label=\"Original Signal\")\n",
    "    for i, mode in enumerate(modes):\n",
    "        plt.plot(t, mode, label=f\"Mode {i+1}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from vmdpy import VMD\n",
    "import torch\n",
    "import torch.fft\n",
    "\n",
    "# VMDPy (CPU-based)\n",
    "def vmdpy_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    VMD using the vmdpy library (CPU implementation).\n",
    "    \"\"\"\n",
    "    u, a, b = VMD(signal, alpha, tau, K, DC, init=1, tol=tol)\n",
    "    return u, a, b\n",
    "\n",
    "# GPU-Accelerated VMD\n",
    "def gpu_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6, device='cuda'):\n",
    "    signal = torch.tensor(signal, dtype=torch.float32, device=device)\n",
    "    N = len(signal)\n",
    "    f_signal = torch.fft.fft(signal)\n",
    "    omega = torch.fft.fftfreq(N, d=1.0).to(device)\n",
    "\n",
    "    u = torch.zeros((K, N), device=device, dtype=torch.complex64)\n",
    "    omega_k = torch.linspace(0, torch.max(omega), K, device=device)\n",
    "    lambda_hat = torch.zeros(N, device=device, dtype=torch.complex64)\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        u_prev = u.clone()\n",
    "        for k in range(K):\n",
    "            omega_shifted = omega - omega_k[k]\n",
    "            denominator = 1 + alpha * (omega_shifted ** 2)\n",
    "            f_u_k = (f_signal - lambda_hat - torch.sum(u, dim=0) + u[k]) / denominator\n",
    "            u[k] = torch.fft.ifft(f_u_k).real\n",
    "        for k in range(K):\n",
    "            omega_k[k] = torch.sum(torch.abs(u[k]) ** 2 * omega) / torch.sum(torch.abs(u[k]) ** 2)\n",
    "        residual = signal - torch.sum(u, dim=0).real\n",
    "        lambda_hat += tau * torch.fft.fft(residual)\n",
    "        if torch.norm(u - u_prev) < tol or iteration > 500:\n",
    "            break\n",
    "        iteration += 1\n",
    "\n",
    "    return u.real.cpu().detach().numpy()\n",
    "\n",
    "def pad_signal(original, reconstructed):\n",
    "    if len(reconstructed) < len(original):\n",
    "        padding = len(original) - len(reconstructed)\n",
    "        reconstructed = np.pad(reconstructed, (0, padding), mode='constant', constant_values=0)\n",
    "    elif len(reconstructed) > len(original):\n",
    "        reconstructed = reconstructed[:len(original)]\n",
    "    return reconstructed\n",
    "\n",
    "# Benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from scipy.io import wavfile\n",
    "    \n",
    "    signal = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0036.wav')[1]\n",
    "\n",
    "    # Generate a synthetic signal\n",
    "    t = np.linspace(0, 1, len(signal))\n",
    "    # signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "    print(\"signal len\", len(signal))\n",
    "    # VMDPy\n",
    "    start_time = time.time()\n",
    "    modes_vmdpy, a ,b = vmdpy_vmd(signal, alpha=200000, tau=0, K=5)\n",
    "    vmdpy_time = time.time() - start_time\n",
    "\n",
    "    # GPU-Accelerated VMD\n",
    "    start_time = time.time()\n",
    "    modes_gpu, c,d = VMD_torch(\n",
    "    f = signal, \n",
    "    alpha=200000,  # adjust as needed\n",
    "    tau=0,       # noise-slack\n",
    "    K=8,         # number of modes\n",
    "    DC=False,     # keep zero frequency mode\n",
    "    init=1,      # uniformly distributed initial omegas\n",
    "    tol=1e-30     # convergence tolerance\n",
    ")\n",
    "    #f, alpha, tau, K, DC, init, tol, device=\"cuda\"\n",
    "    gpu_time = time.time() - start_time\n",
    "\n",
    "    # Calculate reconstruction error\n",
    "    reconstructed_vmdpy = np.sum(modes_vmdpy, axis=0)\n",
    "    reconstructed_gpu = np.sum(modes_gpu, axis=0)\n",
    "\n",
    "    # Pad the reconstructed signals\n",
    "    reconstructed_vmdpy_padded = pad_signal(signal, reconstructed_vmdpy)\n",
    "    reconstructed_gpu_padded = pad_signal(signal, reconstructed_gpu)\n",
    "\n",
    "    # Calculate mean squared errors\n",
    "    mse_vmdpy = mean_squared_error(signal, reconstructed_vmdpy_padded)\n",
    "    mse_gpu = mean_squared_error(signal, reconstructed_gpu_padded)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"VMDPy (CPU): Time = {vmdpy_time:.4f}s, MSE = {mse_vmdpy:.4e}\")\n",
    "    print(f\"GPU-Accelerated VMD: Time = {gpu_time:.4f}s, MSE = {mse_gpu:.4e}\")\n",
    "\n",
    "    # Plot VMDPy results (separate modes)\n",
    "    plt.figure(figsize=(25, 12))\n",
    "    plt.suptitle(\"Decomposed Modes: VMDPy (CPU Implementation)\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_vmdpy):\n",
    "        plt.subplot(len(modes_vmdpy), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"VMDPy Mode {i+1}\", color='blue')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Plot GPU-Accelerated VMD results (separate modes)\n",
    "    plt.figure(figsize=(25, 12))\n",
    "    plt.suptitle(\"Decomposed Modes: GPU-Accelerated VMD\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_gpu):\n",
    "        plt.subplot(len(modes_gpu), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"GPU Mode {i+1}\", color='green')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav', sr=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 6))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(stft_magnitude, ref=np.max),\n",
    "                         sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('STFT Spectrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft\n",
    "\n",
    "# Step 1: Read the audio file\n",
    "samplerate, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "\n",
    "# Ensure the audio is mono (convert if necessary)\n",
    "if data.ndim > 1:\n",
    "    data = data.mean(axis=1)\n",
    "\n",
    "# Step 2: Apply STFT\n",
    "# Define parameters for STFT\n",
    "nperseg = 1024  # Length of each segment\n",
    "f, t, Zxx = stft(data, fs=samplerate, nperseg=nperseg)\n",
    "\n",
    "# Step 3: Filter frequencies up to 1000 Hz\n",
    "freq_limit = 4000\n",
    "freq_indices = f <= freq_limit\n",
    "f_filtered = f[freq_indices]\n",
    "Zxx_filtered = Zxx[freq_indices, :]\n",
    "\n",
    "# Step 4: Plot the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t, f_filtered, np.abs(Zxx_filtered), shading='gouraud', cmap='inferno')\n",
    "plt.title('Spectrogram (STFT) - Frequencies up to 1000 Hz')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "def VMD_GPU(f, alpha, tau, K, DC=False, init=0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    GPU-Accelerated Variational Mode Decomposition\n",
    "    \"\"\"\n",
    "    # Ensure input is on GPU and convert to single precision\n",
    "    f = cp.asarray(f, dtype=cp.float64)\n",
    "    \n",
    "    if len(f) % 2:\n",
    "        f = f[:-1]\n",
    "\n",
    "    # Period and sampling frequency of input signal\n",
    "    fs = cp.float32(1. / len(f))\n",
    "    \n",
    "    ltemp = len(f) // 2 \n",
    "    fMirr = cp.concatenate([cp.flip(f[:ltemp]), f, cp.flip(f[-ltemp:])])\n",
    "\n",
    "    # Time Domain\n",
    "    T = len(fMirr)\n",
    "    t = cp.arange(0, T, dtype=cp.float32) / T\n",
    "    \n",
    "    # Spectral Domain discretization\n",
    "    freqs = cp.fft.fftshift(cp.fft.fftfreq(T, d=1.0))\n",
    "\n",
    "    # Maximum number of iterations\n",
    "    Niter = 500\n",
    "    # Individual alpha for each mode\n",
    "    Alpha = cp.full(K, alpha, dtype=cp.float32)\n",
    "    \n",
    "    # Construct and center f_hat\n",
    "    f_hat = cp.fft.fftshift(cp.fft.fft(fMirr.astype(cp.complex64)))\n",
    "    f_hat_plus = f_hat.copy()\n",
    "    f_hat_plus[:T//2] = 0\n",
    "\n",
    "    # Initialization of omega_k\n",
    "    omega_plus = cp.zeros((Niter, K), dtype=cp.float32)\n",
    "\n",
    "    if init == 1:\n",
    "        omega_plus[0, :] = cp.linspace(0, 0.5, K, dtype=cp.float32)\n",
    "    elif init == 2:\n",
    "        omega_plus[0, :] = cp.sort(cp.exp(cp.log(fs) + (cp.log(0.5) - cp.log(fs)) * cp.random.rand(K, dtype=cp.float32)))\n",
    "    else:\n",
    "        omega_plus[0, :] = 0\n",
    "            \n",
    "    # if DC mode imposed, set its omega to 0\n",
    "    if DC:\n",
    "        omega_plus[0, 0] = 0\n",
    "    \n",
    "    # Start with empty dual variables\n",
    "    lambda_hat = cp.zeros((Niter, len(freqs)), dtype=cp.complex64)\n",
    "    \n",
    "    # Other initializations\n",
    "    uDiff = tol + cp.finfo(cp.float32).eps\n",
    "    n = 0\n",
    "    sum_uk = 0\n",
    "    u_hat_plus = cp.zeros((Niter, len(freqs), K), dtype=cp.complex64)\n",
    "\n",
    "    # Main loop for iterative updates\n",
    "    while (uDiff > tol and n < Niter - 1):\n",
    "        # Update first mode accumulator\n",
    "        k = 0\n",
    "        sum_uk = u_hat_plus[n, :, K-1] + sum_uk - u_hat_plus[n, :, 0]\n",
    "        \n",
    "        # Update spectrum of first mode\n",
    "        u_hat_plus[n + 1, :, k] = (f_hat_plus - sum_uk - lambda_hat[n, :] / 2) / \\\n",
    "                                  (1 + Alpha[k] * (freqs - omega_plus[n, k]) ** 2)\n",
    "        \n",
    "        # Update omega if not held at 0\n",
    "        if not DC:\n",
    "            omega_plus[n + 1, k] = cp.dot(\n",
    "                freqs[T//2:T], cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2) / \\\n",
    "                cp.sum(cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2)\n",
    "\n",
    "        # Update any other mode\n",
    "        for k in range(1, K):\n",
    "            sum_uk = u_hat_plus[n + 1, :, k - 1] + sum_uk - u_hat_plus[n, :, k]\n",
    "            u_hat_plus[n + 1, :, k] = (f_hat_plus - sum_uk - lambda_hat[n, :] / 2) / \\\n",
    "                                      (1 + Alpha[k] * (freqs - omega_plus[n, k]) ** 2)\n",
    "            omega_plus[n + 1, k] = cp.dot(\n",
    "                freqs[T//2:T], cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2) / \\\n",
    "                cp.sum(cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2)\n",
    "            \n",
    "        # Dual ascent\n",
    "        lambda_hat[n + 1, :] = lambda_hat[n, :] + tau * (cp.sum(u_hat_plus[n + 1, :, :], axis=1) - f_hat_plus)\n",
    "        \n",
    "        # Update loop counter and check for convergence\n",
    "        n += 1\n",
    "        uDiff = cp.sum(cp.abs(u_hat_plus[n, :, :] - u_hat_plus[n - 1, :, :]) ** 2).get()\n",
    "            \n",
    "    # Postprocessing and cleanup\n",
    "    Niter = min(Niter, n)\n",
    "    omega = omega_plus[:Niter, :].astype(cp.float32)\n",
    "    \n",
    "    # Reconstruct modes\n",
    "    u_hat = cp.zeros((T, K), dtype=cp.complex64)\n",
    "    u_hat[T//2:T, :] = u_hat_plus[Niter - 1, T//2:T, :]\n",
    "    u_hat[:T//2, :] = cp.conj(u_hat_plus[Niter - 1, T//2:T, :])\n",
    "    \n",
    "    u = cp.zeros((K, len(t)), dtype=cp.float32)\n",
    "    for k in range(K):\n",
    "        u_k = cp.real(cp.fft.ifft(cp.fft.ifftshift(u_hat[:, k])))\n",
    "        # Apply proper window function to reduce edge effects\n",
    "        window = cp.hanning(len(u_k))\n",
    "        u[k, :] = u_k * window\n",
    "    \n",
    "    # 6. Final trimming - ensure proper alignment with original signal\n",
    "    mid_point = len(u[0]) // 2\n",
    "    half_len = len(f) // 2\n",
    "    u = u[:, mid_point-half_len:mid_point+half_len]\n",
    "    \n",
    "    return u.get(), u_hat.get(), omega.get()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def test_vmd_gpu():\n",
    "    # Generate a sample signal\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a sample signal with multiple modes\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    signal = (np.sin(2 * np.pi * 10 * t) +  # 10 Hz component\n",
    "              0.5 * np.sin(2 * np.pi * 20 * t) +  # 20 Hz component\n",
    "              0.25 * np.random.normal(size=t.shape))  # some noise\n",
    "    \n",
    "    # Decompose the signal\n",
    "    modes, mode_spectra, mode_frequencies = VMD_GPU(\n",
    "        signal, \n",
    "        alpha=2000,  # high alpha for tight mode bounds\n",
    "        tau=0,       # noise-slack\n",
    "        K=3,         # number of modes to extract\n",
    "        DC=True,     # keep zero frequency mode\n",
    "        init=1,      # uniformly distributed initial omegas\n",
    "        tol=1e-6     # convergence tolerance\n",
    "    )\n",
    "    \n",
    "    return modes, mode_spectra, mode_frequencies\n",
    "\n",
    "# Uncomment to run the test\n",
    "# modes, spectra, frequencies = test_vmd_gpu()\n",
    "\n",
    "# Optional visualization function\n",
    "def plot_vmd_modes(t, signal, modes):\n",
    "    \"\"\"\n",
    "    Plot the original signal and the decomposed modes.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.plot(t, signal, label=\"Original Signal\", color='black')\n",
    "    plt.plot(t, signal - np.sum(modes, axis=0), label=\"Residual Signal\", color='red')\n",
    "    \n",
    "    for i, mode in enumerate(modes):\n",
    "        plt.plot(t, mode, label=f\"VMDPy Mode {i+1}\", linewidth=1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Decomposed Modes: VMDPy (CPU Implementation)\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate or load your signal\n",
    "# t = np.linspace(0, 1, 1000)\n",
    "# signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 20 * t) + 0.25 * np.random.normal(size=t.shape)\n",
    "t = np.linspace(0, 1, 200000)\n",
    "signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "# Decompose the signal\n",
    "modes, mode_spectra, mode_frequencies = VMD_torch(\n",
    "    signal, \n",
    "    alpha=200000,  # adjust as needed\n",
    "    tau=0,       # noise-slack\n",
    "    K=2,         # number of modes\n",
    "    DC=False,     # keep zero frequency mode\n",
    "    init=2,      # uniformly distributed initial omegas\n",
    "    tol=1e-30     # convergence tolerance\n",
    ")\n",
    "\n",
    "# Optional: Visualize the modes\n",
    "plot_vmd_modes(t, signal, modes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the time array\n",
    "fs = 1000  # Sampling frequency in Hz\n",
    "t = np.linspace(0, 1, fs, endpoint=False)  # Time vector from 0 to 1 second\n",
    "\n",
    "# Define the signal components\n",
    "signal1 = np.sin(2 * np.pi * 10 * t)  # 10 Hz sine wave\n",
    "signal2 = 0.5 * np.sin(2 * np.pi * 50 * t)  # 50 Hz sine wave with 0.5 amplitude\n",
    "\n",
    "# Combine the signals\n",
    "combined_signal = signal1 + signal2\n",
    "\n",
    "plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Plot the 10 Hz component\n",
    "plt.plot(t, signal1, label=\"10 Hz Component\", color=\"blue\", alpha=0.7)\n",
    "\n",
    "# Plot the 50 Hz component\n",
    "plt.plot(t, signal2, label=\"50 Hz Component\", color=\"orange\", alpha=0.7)\n",
    "\n",
    "# Plot the combined signal\n",
    "plt.plot(t, combined_signal, label=\"Combined Signal\", color=\"green\", linewidth=1.5)\n",
    "\n",
    "plt.title(\"Signal Components and Combined Signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
